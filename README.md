# MixFormer

The implementation of the RDT-TEF (RGB-D visual object tracking with transformer-based multi-modal feature fusion)


## Install the environment
Use the Anaconda
```
conda create -n mixformer python=3.8
conda activate mixformer
bash install_pytorch17.sh
```
more information about install can be found in [Mixformer](https://github.com/MCG-NJU/MixFormer)

## Model Zoo and raw results
The trained models and the raw tracking results are provided in the 
[[Models and Raw results]](https://pan.baidu.com/s/1G4MzOGSTMWegTcyr9aP4Lg) (Baidu Driver: rgbd).

<!-- ## Contact
Yutao Cui: cuiyutao@smail.nju.edu.cn  -->

## Acknowledgments
* Thanks for [Mixformer](https://github.com/MCG-NJU/MixFormer) Library and [AlphaRefine
](https://github.com/MasterBin-IIAU/AlphaRefine) Library, which helps us to quickly implement our ideas.


<!-- ## ✏️ Citation

If you think this project is helpful, please feel free to leave a star⭐️ and cite our paper:

```
@inproceedings{cui2022mixformer,
  title={Mixformer: End-to-end tracking with iterative mixed attention},
  author={Cui, Yutao and Jiang, Cheng and Wang, Limin and Wu, Gangshan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13608--13618},
  year={2022}
}
@misc{cui2023mixformer,
      title={MixFormer: End-to-End Tracking with Iterative Mixed Attention}, 
      author={Yutao Cui and Cheng Jiang and Gangshan Wu and Limin Wang},
      year={2023},
      eprint={2302.02814},
      archivePrefix={arXiv}
} -->
<!-- ``` -->
